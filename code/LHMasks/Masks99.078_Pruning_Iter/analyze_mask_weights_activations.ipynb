{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d364bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle\n",
    "random=torch.load(\"../../../models/snli/random_inits.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "26677e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files saved when pruning 20% til 99% --> iter\n",
    "fw99_i=torch.load(\"../Masks99.078_Pruning_Iter/final_weights_99.078_iter.pth\")\n",
    "fw99mask_i=torch.load(\"../Masks99.078_Pruning_Iter/99.08_prune_mask_iter.pt\")\n",
    "with open(\"OrigActivations_iter.pkl\", 'rb') as f:\n",
    "    oga_i = pickle.load(f)\n",
    "oga_i=torch.tensor(oga_i).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "65bbc47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find whcih neurons in the pruning mask are 0'd out\n",
    "mask0 = []\n",
    "for i,j in enumerate(fw99mask_i):\n",
    "    if j.sum() == 0:\n",
    "        #print(fw99_i[i].sum())\n",
    "        mask0.append(i)\n",
    "print(len(mask0))\n",
    "#asserted that those weights are 0'd out\n",
    "co=0\n",
    "for i in mask0:\n",
    "    if torch.unique(oga_i[i]).sum() > 0 :\n",
    "        co += 1\n",
    "        '''print(\"=============== NON 0 ACTIVATIONS ==================\")\n",
    "        print(\"Radnom weights for unit \", i, \": \", random_weights[i])\n",
    "        print(\"Activations for neuron \", i, \": \", oga_i[i])\n",
    "    else:\n",
    "        print(\"=============== 0 ACTIVATIONS ==================\")\n",
    "        print(\"Radnom Weights for unit \", i, \": \", random_weights[i])\n",
    "        print(\"Activations for neuron \", i, \": \", oga_i[i])'''\n",
    "co\n",
    "    #notice most of the activations are 0's but if it's not 0, its all the same value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cf133995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files saved when pruning 99% --> \n",
    "fw99=torch.load(\"../Masks99.078_Pruning_Iter/final_weights_99.078.pth\")\n",
    "fw99mask=torch.load(\"../Masks99.078_Pruning_Iter/99.08_prune_mask.pt\")\n",
    "fw91mask=torch.load(\"../Masks91.41_Pruning_Iter/91.41_prune_mask.pt\")\n",
    "with open(\"OrigActivations.pkl\", 'rb') as f:\n",
    "    oga = pickle.load(f)\n",
    "oga=torch.tensor(oga).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "15ab6a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19336.0 19342.0\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "total_i=0\n",
    "for i in fw99mask:\n",
    "    total+= i.sum().item()\n",
    "for i in fw99mask_i:\n",
    "    total_i+= i.sum().item()\n",
    "print(total,total_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "0214dd47",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k,l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(j):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m             \u001b[38;5;28;01massert\u001b[39;00m fw99mask[i][k]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m, k\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#finding: when u prune directly vs prune interatively the prune masks are not the same (19336.0 vs 19342.0) demoed by this assert\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# pruning iteratively causees many neurons completely 0'd out and out the neurons that have lost all connections\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# some of then have the same value for each sample (3rd cell)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# some of them  are  0's for each input\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# if a neuron has 0's for each input or same value for each, the pruning mask for that neuron is fully 0 and the weights between\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# the prev layer adn that layer are all 0's demoed by cell 3\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 25"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(fw91mask):\n",
    "    for k,l in enumerate(j):\n",
    "        if l == 0:\n",
    "            assert fw99mask[i][k]==0, k\n",
    "#finding: when u prune directly vs prune interatively the prune masks are not the same (19336.0 vs 19342.0) demoed by this assert\n",
    "# pruning iteratively causees many neurons completely 0'd out and out the neurons that have lost all connections\n",
    "    # some of then have the same value for each sample (3rd cell)\n",
    "    # some of them  are  0's for each input\n",
    "# if a neuron has 0's for each input or same value for each, the pruning mask for that neuron is fully 0 and the weights between\n",
    "    # the prev layer adn that layer are all 0's demoed by cell 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c5996807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#find whcih neurons in the pruning mask are 0'd out\n",
    "mask0 = []\n",
    "for i,j in enumerate(fw99mask):\n",
    "    if j.sum() == 0:\n",
    "        mask0.append(i)\n",
    "print(mask0)\n",
    "#asserted that those weights are 0'd out\n",
    "for i in mask0:\n",
    "    print(i, random_weights[i])\n",
    "    print(i, oga[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "48bb48b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907798767089844"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=0\n",
    "for i in fw99mask:\n",
    "    total += i.sum().item()\n",
    "1 - total/(1024*2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cc77278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0212, -0.0134,  0.0191,  ..., -0.0114, -0.0046,  0.0139])\n",
      "3.843656\n",
      "tensor(13., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "unit=10\n",
    "print(random['state_dict']['mlp.0.weight'][unit])\n",
    "print(fw99_i[unit].sum())\n",
    "print(fw99mask_i[unit].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d859a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_weights = random['state_dict']['mlp.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f718b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 tensor([ 0.0218, -0.0074,  0.0075,  ..., -0.0063,  0.0120,  0.0070])\n",
      "4 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "22 tensor([ 0.0031, -0.0219,  0.0216,  ..., -0.0164,  0.0015, -0.0159])\n",
      "22 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "46 tensor([ 0.0180,  0.0067, -0.0041,  ...,  0.0053, -0.0072,  0.0167])\n",
      "46 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "140 tensor([ 0.0187,  0.0027,  0.0067,  ...,  0.0047,  0.0033, -0.0148])\n",
      "140 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "172 tensor([ 0.0065,  0.0017, -0.0028,  ..., -0.0142, -0.0189, -0.0083])\n",
      "172 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "182 tensor([-0.0076,  0.0169, -0.0184,  ...,  0.0207, -0.0057,  0.0134])\n",
      "182 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "194 tensor([ 0.0071, -0.0039, -0.0018,  ..., -0.0164,  0.0024, -0.0046])\n",
      "194 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "214 tensor([-0.0088, -0.0129, -0.0007,  ..., -0.0101,  0.0012, -0.0171])\n",
      "214 tensor([0.1402, 0.1402, 0.1402,  ..., 0.1402, 0.1402, 0.1402])\n",
      "242 tensor([-0.0019, -0.0038, -0.0213,  ..., -0.0120,  0.0136, -0.0201])\n",
      "242 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "248 tensor([ 0.0124,  0.0203, -0.0139,  ...,  0.0078, -0.0094, -0.0008])\n",
      "248 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "263 tensor([ 0.0033,  0.0017, -0.0060,  ..., -0.0187,  0.0167, -0.0049])\n",
      "263 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "292 tensor([ 0.0057, -0.0115,  0.0163,  ...,  0.0193, -0.0003, -0.0017])\n",
      "292 tensor([0.1293, 0.1293, 0.1293,  ..., 0.1293, 0.1293, 0.1293])\n",
      "313 tensor([ 0.0148,  0.0153, -0.0088,  ..., -0.0059,  0.0013,  0.0123])\n",
      "313 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "331 tensor([ 0.0180,  0.0216,  0.0186,  ..., -0.0100,  0.0138,  0.0058])\n",
      "331 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "375 tensor([-0.0112,  0.0100, -0.0218,  ..., -0.0041,  0.0107,  0.0009])\n",
      "375 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "399 tensor([0.0119, 0.0123, 0.0132,  ..., 0.0017, 0.0008, 0.0121])\n",
      "399 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "408 tensor([-0.0107,  0.0208, -0.0070,  ..., -0.0009, -0.0141, -0.0210])\n",
      "408 tensor([0.1159, 0.1159, 0.1159,  ..., 0.1159, 0.1159, 0.1159])\n",
      "415 tensor([-0.0203, -0.0206, -0.0214,  ...,  0.0167,  0.0140,  0.0061])\n",
      "415 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "422 tensor([-0.0109,  0.0109,  0.0218,  ...,  0.0017,  0.0209, -0.0097])\n",
      "422 tensor([0.1154, 0.1154, 0.1154,  ..., 0.1154, 0.1154, 0.1154])\n",
      "426 tensor([-0.0150, -0.0101, -0.0176,  ...,  0.0002,  0.0219, -0.0035])\n",
      "426 tensor([0.1118, 0.1118, 0.1118,  ..., 0.1118, 0.1118, 0.1118])\n",
      "441 tensor([-0.0144,  0.0063,  0.0063,  ..., -0.0023,  0.0022,  0.0183])\n",
      "441 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "484 tensor([ 0.0041,  0.0153, -0.0092,  ...,  0.0093,  0.0144, -0.0030])\n",
      "484 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "499 tensor([-0.0028, -0.0025, -0.0085,  ...,  0.0095, -0.0134, -0.0134])\n",
      "499 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "502 tensor([-0.0076,  0.0220,  0.0029,  ..., -0.0015,  0.0029,  0.0088])\n",
      "502 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "533 tensor([-0.0074,  0.0033,  0.0068,  ..., -0.0005,  0.0163,  0.0115])\n",
      "533 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "545 tensor([ 0.0112, -0.0068, -0.0221,  ...,  0.0157,  0.0106,  0.0086])\n",
      "545 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "550 tensor([ 0.0046, -0.0044,  0.0191,  ..., -0.0138, -0.0099,  0.0074])\n",
      "550 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "553 tensor([ 0.0202,  0.0008,  0.0178,  ..., -0.0086,  0.0130,  0.0027])\n",
      "553 tensor([0.1205, 0.1205, 0.1205,  ..., 0.1205, 0.1205, 0.1205])\n",
      "554 tensor([-0.0172,  0.0140,  0.0100,  ..., -0.0145,  0.0018, -0.0199])\n",
      "554 tensor([0.1206, 0.1206, 0.1206,  ..., 0.1206, 0.1206, 0.1206])\n",
      "569 tensor([ 1.3883e-03,  2.8627e-03,  1.3877e-02,  ...,  3.4073e-05,\n",
      "         9.0296e-03, -9.3589e-03])\n",
      "569 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "573 tensor([ 0.0047, -0.0156,  0.0180,  ..., -0.0220, -0.0142,  0.0107])\n",
      "573 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "597 tensor([-0.0212, -0.0052,  0.0169,  ...,  0.0215, -0.0027,  0.0119])\n",
      "597 tensor([0.1215, 0.1215, 0.1215,  ..., 0.1215, 0.1215, 0.1215])\n",
      "613 tensor([-0.0161, -0.0113,  0.0081,  ...,  0.0120,  0.0070, -0.0161])\n",
      "613 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "628 tensor([ 0.0142, -0.0198, -0.0127,  ...,  0.0155,  0.0117, -0.0110])\n",
      "628 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "631 tensor([ 0.0166, -0.0014, -0.0039,  ..., -0.0066, -0.0075, -0.0069])\n",
      "631 tensor([0.1410, 0.1410, 0.1410,  ..., 0.1410, 0.1410, 0.1410])\n",
      "647 tensor([ 0.0094, -0.0024,  0.0199,  ...,  0.0059, -0.0087,  0.0038])\n",
      "647 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "649 tensor([ 0.0023,  0.0192,  0.0132,  ..., -0.0157,  0.0180,  0.0027])\n",
      "649 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "657 tensor([-0.0121, -0.0216,  0.0209,  ..., -0.0099,  0.0218,  0.0133])\n",
      "657 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "661 tensor([ 0.0196,  0.0188, -0.0208,  ...,  0.0144, -0.0187, -0.0193])\n",
      "661 tensor([0.1202, 0.1202, 0.1202,  ..., 0.1202, 0.1202, 0.1202])\n",
      "696 tensor([-0.0153, -0.0194,  0.0085,  ..., -0.0026,  0.0098, -0.0127])\n",
      "696 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "708 tensor([ 0.0043, -0.0154,  0.0081,  ...,  0.0151,  0.0069,  0.0116])\n",
      "708 tensor([0.1086, 0.1086, 0.1086,  ..., 0.1086, 0.1086, 0.1086])\n",
      "710 tensor([ 0.0105,  0.0111, -0.0135,  ...,  0.0169, -0.0061, -0.0028])\n",
      "710 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "734 tensor([-0.0205, -0.0183, -0.0109,  ...,  0.0065, -0.0055,  0.0067])\n",
      "734 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "770 tensor([-0.0066,  0.0091,  0.0056,  ...,  0.0057,  0.0065,  0.0219])\n",
      "770 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "774 tensor([-1.5585e-02,  3.9190e-06, -1.0459e-02,  ...,  2.0804e-02,\n",
      "        -9.4480e-03, -2.1837e-02])\n",
      "774 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "799 tensor([-0.0082,  0.0113,  0.0037,  ..., -0.0040, -0.0082, -0.0167])\n",
      "799 tensor([0.1013, 0.1013, 0.1013,  ..., 0.1013, 0.1013, 0.1013])\n",
      "810 tensor([-8.1587e-03, -4.6793e-05, -6.1444e-03,  ..., -1.3341e-02,\n",
      "        -1.4592e-02, -1.3812e-02])\n",
      "810 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "820 tensor([-0.0183, -0.0184,  0.0054,  ...,  0.0096,  0.0015, -0.0158])\n",
      "820 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "826 tensor([ 0.0061,  0.0019,  0.0166,  ...,  0.0008, -0.0063, -0.0057])\n",
      "826 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "839 tensor([ 0.0179, -0.0189,  0.0077,  ...,  0.0055, -0.0208, -0.0109])\n",
      "839 tensor([0.1499, 0.1499, 0.1499,  ..., 0.1499, 0.1499, 0.1499])\n",
      "840 tensor([ 0.0027, -0.0195,  0.0042,  ...,  0.0065,  0.0128,  0.0093])\n",
      "840 tensor([0.1370, 0.1370, 0.1370,  ..., 0.1370, 0.1370, 0.1370])\n",
      "869 tensor([ 0.0012, -0.0050, -0.0116,  ...,  0.0139,  0.0119,  0.0124])\n",
      "869 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "887 tensor([ 0.0172, -0.0059, -0.0213,  ..., -0.0207,  0.0044, -0.0028])\n",
      "887 tensor([0.1331, 0.1331, 0.1331,  ..., 0.1331, 0.1331, 0.1331])\n",
      "894 tensor([-0.0156, -0.0168, -0.0158,  ...,  0.0064,  0.0055,  0.0132])\n",
      "894 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "896 tensor([-0.0003,  0.0159,  0.0049,  ..., -0.0181,  0.0076, -0.0119])\n",
      "896 tensor([0.1203, 0.1203, 0.1203,  ..., 0.1203, 0.1203, 0.1203])\n",
      "905 tensor([ 0.0212,  0.0174, -0.0141,  ...,  0.0070,  0.0154,  0.0173])\n",
      "905 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "907 tensor([ 0.0209, -0.0004, -0.0091,  ...,  0.0200,  0.0109,  0.0061])\n",
      "907 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "911 tensor([-0.0109,  0.0152, -0.0051,  ...,  0.0083,  0.0112,  0.0173])\n",
      "911 tensor([0.1474, 0.1474, 0.1474,  ..., 0.1474, 0.1474, 0.1474])\n",
      "938 tensor([ 0.0112, -0.0124, -0.0136,  ..., -0.0082, -0.0071, -0.0176])\n",
      "938 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "962 tensor([ 0.0137, -0.0205, -0.0043,  ...,  0.0109, -0.0009,  0.0096])\n",
      "962 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "973 tensor([-0.0192,  0.0097, -0.0074,  ..., -0.0144,  0.0128, -0.0153])\n",
      "973 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "984 tensor([ 0.0102,  0.0099, -0.0177,  ..., -0.0207,  0.0061,  0.0188])\n",
      "984 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "1013 tensor([-0.0136,  0.0034, -0.0022,  ..., -0.0187,  0.0019,  0.0019])\n",
      "1013 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "#find whcih neurons in the pruning mask are 0'd out\n",
    "mask0 = []\n",
    "for i,j in enumerate(fw99mask_i):\n",
    "    if j.sum() == 0:\n",
    "        mask0.append(i)\n",
    "#asserted that those weights are 0'd out\n",
    "for i in mask0:\n",
    "    print(i, random_weights[i])\n",
    "    print(i, oga_i[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "602b62a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 1\n",
      "292 1\n",
      "408 1\n",
      "422 1\n",
      "426 1\n",
      "553 1\n",
      "554 1\n",
      "597 1\n",
      "631 1\n",
      "661 1\n",
      "708 1\n",
      "799 1\n",
      "839 1\n",
      "840 1\n",
      "887 1\n",
      "896 1\n",
      "911 1\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(oga):\n",
    "    l = len(torch.unique(j))\n",
    "    if l == 1 and j.sum() != 0 :\n",
    "        print(i,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "087c9162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "144\n",
      "288\n",
      "432\n",
      "576\n",
      "720\n",
      "864\n",
      "1008\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(seventy903):\n",
    "    if i % 144 == 0: print(i)\n",
    "    for j,l in enumerate(k):\n",
    "        if  l== 0:\n",
    "            assert ninety908[i,j] == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b03c2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0=[]\n",
    "for i,j in enumerate(ninety908):\n",
    "    if j.sum()==0:\n",
    "        s0.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85a90747",
   "metadata": {},
   "outputs": [],
   "source": [
    "u0=[]\n",
    "for j,i in enumerate(oga):\n",
    "    l=len(torch.unique(i))\n",
    "    if l==1 and torch.unique(i) != 0:\n",
    "        u0.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aeb6fe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f4d1cb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1416, 0.1416, 0.1416,  ..., 0.1416, 0.1416, 0.1416])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oga[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "68d5e8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26., device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninety908[19].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353486ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
