{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "ec387e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models,settings\n",
    "import numpy as np\n",
    "import sklearn.cluster as scikit_cluster\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "187f3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TestRun/OriginalActivations.pkl\", 'rb') as f:\n",
    "    final_activs=pickle.load(f)\n",
    "with open(\"Sentences.pkl\", 'rb') as f:\n",
    "    sents=pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "e0a095ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_activs = np.transpose(np.array(final_activs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "c7c91dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.       , 0.       , 4.7760525, ..., 0.       , 0.       ,\n",
       "       0.       ], dtype=float32)"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_activs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "4e088fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_activ_ranges(num_clusters, neuron, final_actives):\n",
    "    clustering=scikit_cluster.KMeans(n_clusters= num_clusters, random_state=1234).fit(final_actives[neuron].reshape(-1,1))\n",
    "    activation_range= {}\n",
    "    for index, label in enumerate(clustering.labels_):\n",
    "        if label in activation_range.keys():\n",
    "            activation_range[label].append(final_actives[neuron][index])\n",
    "        else:\n",
    "            activation_range[label] = [final_actives[neuron][index]]\n",
    "        activation_range[label].sort()\n",
    "    return sort_dict(activation_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "5a4f2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(activation_range):\n",
    "    ranges = []\n",
    "    activation_range_ = activation_range.values()\n",
    "    activation_range_= sorted(activation_range_, key=lambda item: item[0])\n",
    "    for i in activation_range_:\n",
    "        ranges.append((min(i), max(i)))\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "39122fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_explaining_neurons(cluster):\n",
    "    df = pd.read_csv(f\"TestRun/Cluster{cluster}IOUS1024N.csv\")\n",
    "    return df['unit'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "cdee1c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "775 in find_explaining_neurons(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "259a789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_for_neuron(num_clusters, final_activations, neuron, ranges):\n",
    "    pairs = [] #dict of sets\n",
    "    for cluster in range(num_clusters):\n",
    "        pairs_ = []\n",
    "        for sample, activation in enumerate(final_activations[neuron]):\n",
    "            if activation >= ranges[cluster][0] and activation <= ranges[cluster][1]:\n",
    "                pairs_.append(sample)\n",
    "        pairs.append(pairs_)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "2203c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formula_for_neuron(cluster, neuron):\n",
    "    df = pd.read_csv(f\"TestRun/Cluster{cluster}IOUS1024N.csv\")\n",
    "    return df[df['unit']==neuron].best_name.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "a6100439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurn  Empty DataFrame\n",
      "Columns: [unit, best_name, best_iou]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[644], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_formula_for_neuron\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m775\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[643], line 4\u001b[0m, in \u001b[0;36mget_formula_for_neuron\u001b[0;34m(cluster, neuron)\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestRun/Cluster\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mIOUS1024N.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeurn \u001b[39m\u001b[38;5;124m\"\u001b[39m, df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mneuron])\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/base.py:347\u001b[0m, in \u001b[0;36mIndexOpsMixin.item\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only convert an array of size 1 to a Python scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "get_formula_for_neuron(1, 775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "ca734faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(pairs_indices, sentences):\n",
    "    for i, pairs in enumerate(pairs_indices):\n",
    "        for pair in pairs[:2]:\n",
    "            yield i+1, pair, sentences[2*pair], sentences[(2*pair) + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "3483e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,csv\n",
    "def write_file(file,fields,data):\n",
    "    if os.path.exists(file):\n",
    "        with open(file, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerows(data)\n",
    "    else:\n",
    "        with open(file, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow(fields)\n",
    "            writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786eaf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_activ_ranges(num_clusters, neuron, final_actives):\n",
    "    clustering=scikit_cluster.KMeans(n_clusters= num_clusters, random_state=1234).fit(final_actives[neuron].reshape(-1,1))\n",
    "    activation_range= {}\n",
    "    for index, label in enumerate(clustering.labels_):\n",
    "        if label in activation_range.keys():\n",
    "            activation_range[label].append(final_actives[neuron][index])\n",
    "        else:\n",
    "            activation_range[label] = [final_actives[neuron][index]]\n",
    "        activation_range[label].sort()\n",
    "    return sort_dict(activation_range)\n",
    "def sort_dict(activation_range):\n",
    "    ranges = []\n",
    "    activation_range_ = activation_range.values()\n",
    "    activation_range_= sorted(activation_range_, key=lambda item: item[0])\n",
    "    for i in activation_range_:\n",
    "        ranges.append((min(i), max(i)))\n",
    "    return ranges\n",
    "def find_explaining_neurons(cluster):\n",
    "    df = pd.read_csv(f\"TestRun/Cluster{cluster}IOUS1024N.csv\")\n",
    "    return df['unit'].tolist()\n",
    "def get_samples_for_neuron(num_clusters, final_activations, neuron, ranges):\n",
    "    pairs = [] #dict of sets\n",
    "    for cluster in range(num_clusters):\n",
    "        pairs_ = []\n",
    "        for sample, activation in enumerate(final_activations[neuron]):\n",
    "            if activation >= ranges[cluster][0] and activation <= ranges[cluster][1]:\n",
    "                pairs_.append(sample)\n",
    "        pairs.append(pairs_)\n",
    "    return pairs\n",
    "def get_formula_for_neuron(cluster, neuron):\n",
    "    df = pd.read_csv(f\"TestRun/Cluster{cluster}IOUS1024N.csv\")\n",
    "    return df[df['unit']==neuron].best_name.item()\n",
    "def get_sentences(pairs_indices, sentences):\n",
    "    for i, pairs in enumerate(pairs_indices):\n",
    "        for pair in pairs[:2]:\n",
    "            yield i+1, pair, sentences[2*pair], sentences[(2*pair) + 1]\n",
    "import os,csv\n",
    "def write_file(file,fields,data):\n",
    "    if os.path.exists(file):\n",
    "        with open(file, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerows(data)\n",
    "    else:\n",
    "        with open(file, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow(fields)\n",
    "            writer.writerows(data)\n",
    "num_clusters=[3,4,5,10]\n",
    "import random\n",
    "neurons=find_explaining_neurons(cluster=1)\n",
    "neurons=random.sample(neurons, k=10)\n",
    "for num_cluster in num_clusters:\n",
    "    print(f\"Working on {num_cluster} clusters\")\n",
    "    for neuron in neurons:\n",
    "        print(\"Neuron: \", neuron)\n",
    "        ranges = cluster_activ_ranges(num_clusters=num_cluster, neuron=neuron, final_actives=final_activs)\n",
    "        pairs_indices=get_samples_for_neuron(num_clusters=num_cluster, final_activations=final_activs, neuron=neuron, ranges=ranges)\n",
    "        field=['neuron','cluster','formula', 'pair_num', 'pre', 'hyp']\n",
    "        file=f'TestRun/Results{num_cluster}Cluster.csv'\n",
    "        for cluster, pair_num, p, h in get_sentences(pairs_indices, sents):\n",
    "            formula = get_formula_for_neuron(cluster, neuron)\n",
    "            write_file(file,field,[[neuron, cluster, formula, pair_num, p, h]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "a57ee498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 5 clusters\n",
      "Neuron:  390\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[667], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m neurons:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeuron: \u001b[39m\u001b[38;5;124m\"\u001b[39m, neuron)\n\u001b[0;32m----> 9\u001b[0m     ranges \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_activ_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneuron\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_actives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_activs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     pairs_indices\u001b[38;5;241m=\u001b[39mget_samples_for_neuron(num_clusters\u001b[38;5;241m=\u001b[39mnum_cluster, final_activations\u001b[38;5;241m=\u001b[39mfinal_activs, neuron\u001b[38;5;241m=\u001b[39mneuron, ranges\u001b[38;5;241m=\u001b[39mranges)\n\u001b[1;32m     11\u001b[0m     field\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneuron\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpair_num\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[552], line 9\u001b[0m, in \u001b[0;36mcluster_activ_ranges\u001b[0;34m(num_clusters, neuron, final_actives)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m         activation_range[label] \u001b[38;5;241m=\u001b[39m [final_actives[neuron][index]]\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mactivation_range\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sort_dict(activation_range)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_clusters=[3,4,5,10]\n",
    "import random\n",
    "neurons=find_explaining_neurons(cluster=1)\n",
    "neurons=random.sample(neurons, k=10)\n",
    "for num_cluster in num_clusters:\n",
    "    print(f\"Working on {num_cluster} clusters\")\n",
    "    for neuron in neurons:\n",
    "        print(\"Neuron: \", neuron)\n",
    "        ranges = cluster_activ_ranges(num_clusters=num_cluster, neuron=neuron, final_actives=final_activs)\n",
    "        pairs_indices=get_samples_for_neuron(num_clusters=num_cluster, final_activations=final_activs, neuron=neuron, ranges=ranges)\n",
    "        field=['neuron','cluster','formula', 'pair_num', 'pre', 'hyp']\n",
    "        file=f'TestRun/Results{num_cluster}Cluster.csv'\n",
    "        for cluster, pair_num, p, h in get_sentences(pairs_indices, sents):\n",
    "            formula = get_formula_for_neuron(cluster, neuron)\n",
    "            write_file(file,field,[[neuron, cluster, formula, pair_num, p, h]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "586cc648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8192 in pairs_indices[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "271a575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "l=list(sam)\n",
    "print(len(l))\n",
    "#for i in l:\n",
    " #   print(i, sents[2*i], sents[(2*i)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clus4=[]\n",
    "for l, a in zip(c.labels_, final_activs[6]):\n",
    "    if l==1:\n",
    "        clus4.append(a.item())\n",
    "print(clus4)\n",
    "sam=set()\n",
    "for a in clus4:\n",
    "    for i in np.where(final_activs[6]>a)[0]:\n",
    "        sam.add(i)\n",
    "sam\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "9b762e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 2048]),\n",
       " tensor([[ 0.1208, -0.7709,  1.4369,  ..., -0.8955, -1.2836, -0.1834],\n",
       "         [-0.6939,  0.7449, -0.5268,  ...,  0.1234,  0.3660,  0.1675],\n",
       "         [-0.2353,  2.4709,  1.5476,  ..., -0.1652, -0.8350, -1.2371],\n",
       "         ...,\n",
       "         [-1.1260, -0.8813, -0.0670,  ...,  0.5094, -0.6077, -0.0805],\n",
       "         [ 0.2784,  0.0794, -1.5159,  ..., -0.1675,  0.5769,  0.2123],\n",
       "         [-1.5695,  0.1398,  0.7238,  ...,  0.2344, -1.0602, -0.0582]]))"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weight=torch.randn(1024,2048)\n",
    "final_weight.shape, final_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9b62e35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1396.9832)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "cd1a2daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 0.0000000e+00 3.1314639e-07 ... 4.9532766e+00 4.9900460e+00\n",
      " 5.0430379e+00]\n",
      "104858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827/2280124660.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_mask= torch.where(torch.abs(torch.tensor(final_weight_t)) <= cutoff, torch.zeros(mask.shape), mask)\n",
      "/tmp/ipykernel_827/2280124660.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_weights= torch.where(torch.abs(torch.tensor(final_weight_t)) <= cutoff, torch.zeros(mask.shape), torch.tensor(final_weight_t))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 0.]]),\n",
       " torch.Size([2048, 1024]))"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weight_t=final_weight.t()\n",
    "mask=torch.ones(final_weight_t.shape)\n",
    "sorted_weights = np.sort(np.abs(final_weight_t[mask == 1]))\n",
    "print(sorted_weights)\n",
    "# Determine the cutoff for weights to be pruned.\n",
    "\n",
    "cutoff_index = np.round(0.05 * sorted_weights.size).astype(int)\n",
    "print(cutoff_index)\n",
    "cutoff = sorted_weights[cutoff_index - 1] \n",
    "# Prune all weights below the cutoff.\n",
    "\n",
    "new_mask= torch.where(torch.abs(torch.tensor(final_weight_t)) <= cutoff, torch.zeros(mask.shape), mask)\n",
    "new_weights= torch.where(torch.abs(torch.tensor(final_weight_t)) <= cutoff, torch.zeros(mask.shape), torch.tensor(final_weight_t))\n",
    "new_mask, new_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d5db3d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 0.0000000e+00 3.1314639e-07 ... 4.9532766e+00 4.9900460e+00\n",
      " 5.0430379e+00]\n",
      "104858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827/179194577.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_mask= torch.where(torch.abs(torch.tensor(final_weight)) <= cutoff, torch.zeros(mask.shape), mask)\n",
      "/tmp/ipykernel_827/179194577.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_weights_= torch.where(torch.abs(torch.tensor(final_weight)) <= cutoff, torch.zeros(mask.shape), torch.tensor(final_weight))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 0.]]),\n",
       " torch.Size([1024, 2048]))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask=torch.ones(final_weight.shape)\n",
    "sorted_weights = np.sort(np.abs(final_weight[mask == 1]))\n",
    "print(sorted_weights)\n",
    "# Determine the cutoff for weights to be pruned.\n",
    "\n",
    "cutoff_index = np.round(0.05 * sorted_weights.size).astype(int)\n",
    "print(cutoff_index)\n",
    "cutoff = sorted_weights[cutoff_index - 1] \n",
    "# Prune all weights below the cutoff.\n",
    "\n",
    "new_mask= torch.where(torch.abs(torch.tensor(final_weight)) <= cutoff, torch.zeros(mask.shape), mask)\n",
    "new_weights_= torch.where(torch.abs(torch.tensor(final_weight)) <= cutoff, torch.zeros(mask.shape), torch.tensor(final_weight))\n",
    "new_mask, new_weights_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "7298b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(new_weights_.t(),new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "53718741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# Read the list of lists from the pickle file\n",
    "with open(\"weights_postcopy.pkl\", 'rb') as f:\n",
    "    weights_postcopy=pickle.load(f)\n",
    "with open(\"weights_precopy.pkl\", 'rb') as f:\n",
    "    weights_pre_copy=pickle.load(f)\n",
    "with open(\"dead_neurons.pkl\", 'rb') as f:\n",
    "    d=pickle.load(f)\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d5adc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,w in enumerate(weights_postcopy):\n",
    "    if w.sum() == 0:\n",
    "        assert i in d\n",
    "    else:\n",
    "        assert not i in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c3e4350e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1021,  0.1023,  0.0403,  ...,  0.2561,  0.0333,  0.1069],\n",
       "        [ 0.0402,  0.0016, -0.0737,  ...,  0.0378,  0.0548, -0.0057],\n",
       "        [-0.1801,  0.1012,  0.1627,  ...,  0.0704, -0.1102, -0.0075],\n",
       "        ...,\n",
       "        [-0.0222,  0.0016, -0.0726,  ...,  0.0095, -0.1076, -0.0332],\n",
       "        [-0.0225,  0.0399,  0.0214,  ...,  0.0184, -0.0385, -0.1041],\n",
       "        [ 0.1054, -0.0383,  0.0160,  ..., -0.0532, -0.4026, -0.0549]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,w in enumerate(weights_pre_copy):\n",
    "    if i in d:\n",
    "        pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3c7cd90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1021,  0.1023,  0.0403,  ...,  0.2561,  0.0333,  0.1069],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-0.0222,  0.0016, -0.0726,  ...,  0.0095, -0.1076, -0.0332],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1054, -0.0383,  0.0160,  ..., -0.0532, -0.4026, -0.0549]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_postcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8604eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "listt=[1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 18, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 68, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 84, 88, 90, 91, 93, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 130, 131, 135, 136, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 172, 174, 175, 177, 178, 180, 182, 183, 184, 186, 187, 188, 189, 190, 193, 194, 195, 196, 199, 200, 201, 202, 205, 206, 207, 208, 210, 211, 212, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 233, 235, 236, 237, 240, 242, 243, 245, 246, 249, 250, 251, 252, 255, 256, 258, 259, 263, 264, 266, 268, 269, 271, 272, 273, 274, 276, 277, 278, 279, 281, 282, 286, 289, 291, 295, 299, 300, 301, 303, 305, 306, 310, 311, 313, 314, 315, 317, 318, 319, 321, 322, 323, 324, 325, 327, 329, 330, 331, 333, 334, 335, 337, 338, 339, 340, 342, 343, 344, 345, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 361, 363, 364, 365, 366, 370, 371, 372, 373, 374, 379, 381, 383, 384, 388, 393, 394, 396, 397, 398, 401, 402, 405, 406, 407, 408, 409, 414, 415, 417, 418, 419, 421, 422, 425, 426, 427, 428, 430, 431, 432, 433, 438, 439, 440, 441, 442, 443, 444, 446, 447, 449, 451, 452, 453, 455, 456, 459, 460, 461, 464, 465, 467, 468, 469, 471, 472, 474, 475, 476, 477, 479, 481, 482, 484, 485, 488, 489, 490, 492, 493, 494, 496, 503, 504, 505, 508, 509, 513, 518, 519, 520, 521, 526, 529, 530, 531, 532, 535, 538, 539, 541, 542, 544, 545, 546, 547, 548, 550, 551, 552, 554, 555, 556, 558, 559, 560, 561, 562, 564, 567, 568, 569, 570, 571, 573, 574, 576, 580, 581, 582, 583, 585, 586, 587, 589, 591, 592, 594, 595, 596, 597, 598, 599, 600, 603, 607, 608, 610, 611, 612, 613, 616, 617, 621, 622, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 637, 638, 639, 641, 642, 644, 645, 646, 648, 649, 650, 651, 653, 654, 655, 657, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 677, 678, 680, 681, 682, 683, 684, 686, 687, 688, 690, 692, 693, 694, 695, 696, 697, 701, 702, 704, 706, 707, 708, 709, 711, 712, 713, 714, 717, 718, 720, 721, 722, 724, 726, 727, 728, 730, 731, 734, 735, 736, 737, 739, 740, 746, 747, 748, 749, 751, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 766, 767, 768, 769, 770, 772, 774, 777, 778, 779, 780, 781, 783, 784, 785, 786, 788, 789, 790, 792, 794, 795, 797, 799, 801, 802, 803, 804, 806, 807, 808, 809, 810, 811, 812, 814, 815, 816, 817, 818, 819, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 834, 835, 836, 838, 839, 840, 841, 843, 844, 845, 846, 847, 848, 849, 851, 852, 853, 855, 856, 857, 860, 862, 863, 866, 867, 868, 869, 871, 872, 873, 876, 877, 878, 879, 880, 881, 883, 884, 887, 888, 889, 890, 891, 893, 894, 896, 897, 898, 899, 900, 901, 902, 903, 904, 906, 909, 910, 911, 912, 914, 915, 916, 918, 920, 921, 923, 927, 928, 929, 930, 931, 933, 935, 937, 938, 940, 942, 943, 944, 945, 946, 948, 950, 951, 952, 953, 954, 955, 956, 958, 960, 961, 962, 964, 965, 966, 967, 968, 969, 971, 973, 974, 975, 976, 978, 981, 984, 985, 987, 988, 989, 991, 992, 993, 994, 995, 996, 997, 999, 1001, 1002, 1003, 1004, 1005, 1006, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1022] \n",
    "for i in range(1024):\n",
    "    if i  in listt:\n",
    "        assert torch.load(\"Cluster4masks.pt\")[i].sum()==0\n",
    "        assert torch.load(\"Cluster3masks.pt\")[i].sum()==0\n",
    "        assert torch.load(\"Cluster2masks.pt\")[i].sum()==0\n",
    "        assert torch.load(\"Cluster1masks.pt\")[i].sum()==0, i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccfa907",
   "metadata": {},
   "source": [
    "## b=torch.randn(10)\n",
    "b=b.reshape(1,-1)\n",
    "print(b.shape)\n",
    "clusters = scikit_cluster.KMeans(n_clusters= 5, random_state=1234).fit(b.t())\n",
    "clusters.labels_ , b.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f36a4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones=0\n",
    "twos=0\n",
    "threes=0\n",
    "fours=0\n",
    "fives=0\n",
    "for i in clusters.labels_:\n",
    "    if i==1:\n",
    "        ones+=1\n",
    "    elif i==2:\n",
    "        twos+=1\n",
    "    elif i==3:\n",
    "        threes+=1\n",
    "    elif i==4:\n",
    "        fours+=1\n",
    "    else:\n",
    "        fives+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b6d9b2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 1, 1, 2)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones, twos, threes, fours, fives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "114c2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = scikit_cluster.KMeans(n_clusters= 5, random_state=1234).fit(b.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " scikit_cluster.KMeans(n_clusters= 5, random_state=1234).fit(b.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3c33f311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 0, 2, 0, 2, 4, 4, 1, 4, 0], dtype=int32),\n",
       " tensor([[-2.1231],\n",
       "         [ 0.2412],\n",
       "         [-0.5005],\n",
       "         [ 0.7508],\n",
       "         [-0.8402],\n",
       "         [-0.0667],\n",
       "         [-0.2084],\n",
       "         [-1.3324],\n",
       "         [-0.1226],\n",
       "         [ 0.3313]]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.labels_ , b.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "211d5c68",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1024) must match the size of tensor b (2048) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m c1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncMasks/Masks0.0\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mPruned/Cluster1masks.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m m0c1\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload(c1)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm0w\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm0c1\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (2048) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "c1=\"IncMasks/Masks0.0%Pruned/Cluster1masks.pt\"\n",
    "m0c1=torch.load(c1)\n",
    "torch.masked_select(m0w,m0c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15dbc5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 1024)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch,settings,models\n",
    "ckpt = torch.load(f\"../{settings.MODEL}\", map_location=\"cpu\")\n",
    "clf = models.BowmanEntailmentClassifier\n",
    "enc = models.TextEncoder(len(ckpt[\"stoi\"]))\n",
    "model=clf(enc)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "model.mlp[0].weight.t().detach().cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0dba87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6631,  1.0282,  0.0766, -0.3954],\n",
      "        [-1.7383, -0.3737, -0.1654,  1.2035]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 1.,  ..., 0., 0., 1.],\n",
       "         [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 1.,  ..., 1., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 1., 0., 1.],\n",
       "         [1., 0., 0.,  ..., 0., 1., 1.]]),\n",
       " tensor([[ 0.1021,  0.0000, -0.1801,  ...,  0.0000,  0.0000,  0.1054],\n",
       "         [ 0.1023,  0.0000,  0.1012,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0737,  0.1627,  ..., -0.0726,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.2561,  0.0000,  0.0704,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.1102,  ..., -0.1076,  0.0000, -0.4026],\n",
       "         [ 0.1069,  0.0000,  0.0000,  ...,  0.0000, -0.1041, -0.0549]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=torch.randn(2,4)\n",
    "print(n)\n",
    "def prune_by_percent_once(percent, mask, final_weight):\n",
    "    # Put the weights that aren't masked out in sorted order.\n",
    "    sorted_weights = np.sort(np.abs(final_weight[mask != 0]))\n",
    "\n",
    "    # Determine the cutoff for weights to be pruned.\n",
    "    \n",
    "    cutoff_index = np.round(percent * sorted_weights.size).astype(int)\n",
    "    cutoff = sorted_weights[cutoff_index - 1] \n",
    "    # Prune all weights below the cutoff.\n",
    "    new_mask= torch.where(torch.abs(torch.tensor(final_weight)) <= cutoff, torch.zeros(mask.shape), mask)\n",
    "    \n",
    "    new_weights= torch.where(torch.abs(torch.tensor(final_weight)) <= cutoff, torch.zeros(mask.shape), torch.tensor(final_weight))\n",
    "    return new_mask, new_weights\n",
    "prune_by_percent_once(0.5, torch.ones(weights.shape),weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b32fff28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_metrics_dir = \"../models/snli/Inc/prune_metrics/0.5%Pruned/model_best.pth\"\n",
    "weights=torch.load(f\"{prune_metrics_dir}\")['state_dict']\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5492d54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.54999923706055"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.where(model.mlp[0].weight==0,1,0).sum()/100\n",
    "a.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9bc3558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.mlp[0].weight.t().detach().cpu().numpy()\n",
    "weights[d] = np.zeros((1,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "350ebb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1020597 ,  0.04020922, -0.18008865, ..., -0.02218907,\n",
       "        -0.02251127,  0.10539793],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.25605595,  0.03776345,  0.07038172, ...,  0.00953927,\n",
       "         0.01841197, -0.0531592 ],\n",
       "       [ 0.0333262 ,  0.05475619, -0.11017767, ..., -0.10764154,\n",
       "        -0.03854869, -0.40262905],\n",
       "       [ 0.1068556 , -0.00570201, -0.00749541, ..., -0.03318856,\n",
       "        -0.10414948, -0.05488989]], dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe66b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm,nw=prune_by_percent_once(0.5, torch.ones(weights.shape),weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7433cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=torch.ones(weights.shape)\n",
    "final_weight=np.sort(np.abs(weights>0)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9c5e57e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "#model.mlp[0].weight.t().detach().cpu().copy_(nw)\n",
    "print(torch.where(model.mlp[0].weight.t().detach().cpu() != nw,1,0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85826df4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mwhere(torch\u001b[38;5;241m.\u001b[39mabs(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mfinal_weight\u001b[49m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, torch\u001b[38;5;241m.\u001b[39mzeros(mask\u001b[38;5;241m.\u001b[39mshape), mask)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_weight' is not defined"
     ]
    }
   ],
   "source": [
    "a=torch.where(torch.abs(torch.tensor(final_weight)) == 1, torch.zeros(mask.shape), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31afa82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(model.mlp[0].weight.t().detach().cpu(),nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4cec86c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((torch.where(model.mlp[0].weight.t()==0,1,0).sum()/(1024*2048)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "800ec238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OR(4, 5)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import formula as FM\n",
    "l=[1,2,3]\n",
    "FM.Or(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7c37e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
